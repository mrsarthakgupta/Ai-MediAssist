## ğŸ©º Medivoice â€” AI Medical Voice Assistant  
**Author: Sarthak Gupta**  
<br>
**Live Demo:** https://ai-medi-assist-nu.vercel.app  
<br>
Medivoice is an **AI-powered voice assistant for healthcare**, designed to make medical interactions smarter, faster, and more human-centric.  
It enables **real-time symptom analysis, prescription support, and health record automation** â€” reducing clinical workload while empowering patients with compassionate AI.

---

## âœ¨ Features

- ğŸ™ **Voice-Enabled Interaction** â€” Natural, conversational interface with speech-to-text & text-to-speech support.
- ğŸ§¾ **Real-Time Symptom Analysis** â€” Patients can describe symptoms and receive instant AI-powered insights.
- ğŸ’Š **Smart Prescription Support** â€” Suggests or validates prescriptions with dosage checks (assistive only).
- ğŸ“‘ **Health Record Automation** â€” Automatically stores and organizes medical conversations into digital records.
- ğŸ§‘â€âš•ï¸ **Doctorâ€“Patient Bridge** â€” Enhances communication, reduces repetitive tasks, and supports decision-making.
- ğŸ”’ **Privacy by Design** â€” Focus on secure handling of sensitive medical data.

---

## ğŸ–¼ Preview

> _Screenshots / Demo GIFs go here_
> Example:

<img width="1919" height="1031" alt="image" src="https://github.com/user-attachments/assets/8fb3fd3e-d280-4e62-94f3-b2eaa2df0ac9" />

<img width="1919" height="1018" alt="image" src="https://github.com/user-attachments/assets/30020479-576d-4753-87e8-6374ea86e2bb" />

---

## ğŸ›  Tech Stack

| Layer                  | Technology                                      |
| ---------------------- | ----------------------------------------------- |
| **Frontend**     | Next.js, React, TailwindCSS                     |
| **Backend**      | Node.js (Express) / Python (FastAPI)            |
| **Speech AI**    | OpenAI Whisper / ElevenLabs / Google Speech API |
| **Voice Output** | ElevenLabs TTS / AWS Polly                      |
| **Database**     | PostgreSQL / MongoDB / Drizzle ORM              |
| **Deployment**   | Vercel / Docker / Render / Railway              |

---

## ğŸš€ Getting Started

Follow these steps to set up and run the Medivoice project locally.

### Prerequisites

- **Node.js** (v18 or higher)
- **npm**, **yarn**, **pnpm**, or **bun** (package manager of your choice)
- **Git** (for cloning the repository)
- (Optional) **Docker** (for containerized deployment)
- (Optional) API keys for Speech AI services (e.g., OpenAI Whisper, ElevenLabs, Google Speech API, AWS Polly)

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/mrsarthakgupta/Ai-MediAssist.git
cd Ai-MediAssist
```

### 2ï¸âƒ£ Install Dependencies

Install the required packages using your preferred package manager:

```bash
# Using npm
npm install

# Or using yarn
yarn install

# Or using pnpm
pnpm install

# Or using bun
bun install
```

### 3ï¸âƒ£ Configure Environment Variables

Create a `.env` file in the root directory and add the necessary environment variables. Example:

```env
DATABASE_URL=
NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=
CLERK_SECRET_KEY=
NEXT_PUBLIC_CLERK_SIGN_IN_URL=
NEXT_PUBLIC_CLERK_SIGN_IN_FALLBACK_REDIRECT_URL=
NEXT_PUBLIC_CLERK_SIGN_UP_FALLBACK_REDIRECT_URL=
NEXT_PUBLIC_CLERK_SIGN_UP_URL=
NEXT_PUBLIC_CLERK_SIGN_UP_FALLBACK_REDIRECT_URL=
NEXT_PUBLIC_CLERK_SIGN_IN_FALLBACK_REDIRECT_URL=
OPEN_ROUTER_API_KEY=
NEXT_PUBLIC_VAPI_API_KEY=
NEXT_PUBLIC_VAPI_VOICE_ASSISTANT_ID=
```

### 4ï¸âƒ£ Run the Development Server

Start the development server with:

```bash
# Using npm
npm run dev

# Or using yarn
yarn dev

# Or using pnpm
pnpm dev

# Or using bun
bun dev
```

Open [http://localhost:3000](http://localhost:3000) in your browser to view the application.

### 5ï¸âƒ£ Edit and Explore

- Start editing the project by modifying `app/page.tsx`. The page will auto-update as you make changes.
- Explore the codebase to customize features like symptom analysis, prescription support, or health record automation.

### 6ï¸âƒ£ Deployment Options

â–¶ Vercel (Recommended)
1. Push the repository to GitHub  
2. Connect your project to **Vercel**  
3. Add `.env` values under **Environment Variables**  
4. Click **Deploy** ğŸš€  

â–¶ Docker
```bash
docker build -t medivoice .
docker run -p 3000:3000 medivoice
```
â–¶ Render / Railway
1. Create a new Web Service
2. Add all required Environment Variables
3. Choose your branch & deploy
4. The server will auto-build and start ğŸ¯

## ğŸ“‚ Project Structure

<details>
<summary><strong>ğŸ“¦ Click to expand the full project structure</strong></summary>

    Ai-MediAssist/
    â”‚â”€â”€ app/              # Next.js App Router pages & routes
    â”‚â”€â”€ components/       # UI components
    â”‚â”€â”€ config/           # Configurations
    â”‚â”€â”€ context/          # Global Context
    â”‚â”€â”€ drizzle/          # Database schema & ORM
    â”‚â”€â”€ lib/              # Helpers & utilities
    â”‚â”€â”€ public/           # Static assets
    â”‚â”€â”€ shared/           # Common logic
    â”‚â”€â”€ .env              # Environment variables
    â”‚â”€â”€ next.config.ts    # Next.js config
    â”‚â”€â”€ tsconfig.json     # TypeScript config
    â”‚â”€â”€ package.json
    â”‚â”€â”€ README.md

</details>
  
## ğŸ“Œ Future Improvements (Roadmap)
-  ğŸ—£ï¸ Multi-language speech support
-  ğŸ¥ Doctor dashboard with patient history  
-  ğŸ¤ HIPAA/GDPR compliant storage 
 
## ğŸ¯ Summary
Medivoice is an AI-powered medical voice assistant that enables real-time symptom analysis, prescription support, and automated medical record generation. Built to showcase modern full-stack + AI integration in a healthcare workflow.

## â­ Author

**Sarthak Gupta**
<br>
Full Stack Developer â€” AI Â· Next.js Â· Node Â· Cloud

If you like this project, consider â­ starring the repo!
